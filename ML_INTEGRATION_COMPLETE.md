# üöÇ Complete ML Integration Workflow

## Architecture Overview

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        FRONTEND                             ‚îÇ
‚îÇ         Dashboard with Pre-Conflict Alerts                  ‚îÇ
‚îÇ    (Shows both ML predictions & pattern-based alerts)       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ HTTP/REST
                     ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    BACKEND (Port 5000)                      ‚îÇ
‚îÇ             Node.js/Express API Gateway                     ‚îÇ
‚îÇ    - Proxies requests to Digital Twin                       ‚îÇ
‚îÇ    - Serves active trains data                              ‚îÇ
‚îÇ    - Routes /api/digital-twin/ml/predictions                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ                        ‚îÇ
             ‚Üì                        ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   DIGITAL TWIN         ‚îÇ  ‚îÇ  ML INTEGRATION SERVICE         ‚îÇ
‚îÇ   (Port 5002)          ‚îÇ  ‚îÇ  (Python Background Monitor)     ‚îÇ
‚îÇ   FastAPI              ‚îÇ‚Üê‚îÄ‚î§                                  ‚îÇ
‚îÇ                        ‚îÇ  ‚îÇ  Every 30 seconds:               ‚îÇ
‚îÇ  ‚Ä¢ /api/v1/ml/         ‚îÇ  ‚îÇ  1. Fetch active trains          ‚îÇ
‚îÇ    predictions (POST)  ‚îÇ  ‚îÇ  2. Group by network             ‚îÇ
‚îÇ  ‚Ä¢ /api/v1/ml/         ‚îÇ  ‚îÇ  3. Call ML API                  ‚îÇ
‚îÇ    predictions (GET)   ‚îÇ  ‚îÇ  4. Store in Digital Twin        ‚îÇ
‚îÇ                        ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ  Stores predictions in ‚îÇ                 ‚îÇ
‚îÇ  Qdrant with embeddings‚îÇ                 ‚Üì
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
             ‚îÇ              ‚îÇ     ML PREDICTION API           ‚îÇ
             ‚Üì              ‚îÇ     (Port 5003)                 ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ     Flask Server                ‚îÇ
‚îÇ   QDRANT VECTOR DB      ‚îÇ‚îÇ                                  ‚îÇ
‚îÇ   (Cloud/Local)         ‚îÇ‚îÇ  ‚Ä¢ Loads trained model           ‚îÇ
‚îÇ                         ‚îÇ‚îÇ  ‚Ä¢ Aggregates train data         ‚îÇ
‚îÇ  Collection:            ‚îÇ‚îÇ  ‚Ä¢ Predicts conflict probability ‚îÇ
‚îÇ  pre_conflict_memory    ‚îÇ‚îÇ  ‚Ä¢ Returns risk level            ‚îÇ
‚îÇ                         ‚îÇ‚îÇ  ‚Ä¢ Identifies factors            ‚îÇ
‚îÇ  Stores:                ‚îÇ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ  ‚Ä¢ ML predictions       ‚îÇ
‚îÇ  ‚Ä¢ Pattern-based alerts ‚îÇ
‚îÇ  ‚Ä¢ Historical conflicts ‚îÇ
‚îÇ  ‚Ä¢ Embeddings for search‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üîÑ Data Flow

### 1. **ML Prediction Generation**

```
Active Trains ‚Üí ML Integration Service ‚Üí ML API
                                          ‚Üì
                                    Predict Conflict
                                          ‚Üì
                            {probability: 0.67, risk: HIGH}
```

### 2. **Storage in Digital Twin**

```
ML Prediction ‚Üí Digital Twin /api/v1/ml/predictions
                      ‚Üì
              Generate Embedding
                      ‚Üì
              Store in Qdrant
                      ‚Üì
         pre_conflict_memory collection
```

### 3. **Frontend Retrieval**

```
Frontend ‚Üí Backend ‚Üí Digital Twin /api/v1/ml/predictions
                            ‚Üì
                    Query Qdrant
                            ‚Üì
                Return ML predictions + pattern alerts
                            ‚Üì
            Display in Pre-Conflict Alerts section
```

## üì¶ Components Integration

### 1. ML Prediction API (`ai-service/ml_prediction_api.py`)

**Purpose:** Serves the trained ML model via REST API

**Endpoints:**
- `POST /api/ml/analyze-network` - Analyze live network state
- `GET /api/ml/health` - Health check
- `GET /api/ml/model-info` - Model metadata

**Flow:**
```python
Train Data ‚Üí Aggregate to Network Level ‚Üí Predict ‚Üí Return {
    prediction: true/false,
    probability: 0.67,
    risk_level: "HIGH",
    contributing_factors: [...],
    recommended_action: "..."
}
```

### 2. ML Integration Service (`ai-service/ml_integration_service.py`)

**Purpose:** Monitors networks and automatically generates ML predictions

**Process:**
```
1. Fetch active trains from backend every 30s
2. Group trains by network_id
3. For each network:
   a. Call ML API to predict conflict
   b. If conflict predicted (probability > 40%):
      - Store in Digital Twin via /api/v1/ml/predictions
      - Digital Twin stores in Qdrant
      - Frontend displays alert
```

**Logging:**
```
[14:30:00] Iteration 42
----------------------------------------
Found 1,247 active trains
Analyzing 15 networks

  Network: FS (386 trains)
    Probability: 67.3%
    Risk Level: HIGH
    ‚ö†Ô∏è  CONFLICT PREDICTED!
    ‚úì ML prediction stored in Qdrant (ID: ml-pred-1706472823.45)
```

### 3. Digital Twin ML Endpoints (`digital-twin/app/api/routes/ml_predictions.py`)

**New Routes Added:**

#### `POST /api/v1/ml/predictions`
Stores ML prediction in Qdrant:
```python
{
    "network_id": "FS",
    "conflict_probability": 0.67,
    "risk_level": "HIGH",
    "contributing_factors": [
        "High anomaly rate (35%)",
        "Significant delays (22%)"
    ],
    ...
}
```

**Process:**
1. Receives ML prediction
2. Generates text embedding
3. Stores in `pre_conflict_memory` collection
4. Returns confirmation

#### `GET /api/v1/ml/predictions`
Retrieves ML predictions from Qdrant:
```
Query params:
- limit: max results (default 50)
- network_id: filter by network
- min_probability: minimum threshold

Returns: Array of ML prediction alerts
```

### 4. Backend Proxy (`backend/server.js`)

**Added Routes:**
```javascript
POST /api/digital-twin/ml/predictions
GET  /api/digital-twin/ml/predictions
```

Proxies requests to Digital Twin API.

### 5. Frontend Component (`frontend/src/components/PreConflictAlerts.js`)

**Updated to:**
- Fetch both pattern-based alerts AND ML predictions
- Combine into single alert list
- Display source (ml_model vs pattern_matching)
- Show risk levels with color coding

**Visual Indicators:**
- üî¥ CRITICAL (‚â•80% probability)
- üü† HIGH (‚â•60% probability)
- üü° MEDIUM (‚â•40% probability)

## üöÄ Complete Startup Sequence

### Terminal 1: Start All Core Services
```bash
.\start-all.bat
```
This starts:
- Backend (port 5000)
- Digital Twin (port 5002)
- Frontend (port 3000)
- AI Service (port 5001)

### Terminal 2: Start ML Prediction API
```bash
.\start-ml-api.bat
```
Loads model and serves on port 5003

### Terminal 3: Start ML Integration Service
```bash
.\start-ml-integration.bat
```
Begins monitoring and generating predictions

## ‚úÖ Verification Steps

### 1. Check ML API is Running
```bash
curl http://localhost:5003/api/ml/health
```

Expected:
```json
{
  "status": "healthy",
  "model_loaded": true
}
```

### 2. Test ML Integration
```bash
python ai-service/test_ml_api.py
```

### 3. Check Qdrant Storage
```bash
curl http://localhost:5000/api/digital-twin/ml/predictions?limit=5
```

Should return recent ML predictions.

### 4. View in Frontend
1. Open http://localhost:3000
2. Navigate to Dashboard
3. Check **Pre-Conflict Alerts** section
4. Should see alerts with source "ML Model" or "Pattern Matching"

## üìä Qdrant Integration Details

### Collection: `pre_conflict_memory`

**Stores:**
- ML predictions from the model
- Pattern-based preventive alerts
- Historical pre-conflict states

**Structure:**
```javascript
{
  id: "uuid",
  vector: [384-dimensional embedding],
  payload: {
    prediction_id: "ml-pred-xxx",
    network_id: "FS",
    source: "ml_prediction",
    probability: 0.67,
    risk_level: "HIGH",
    contributing_factors: "...",
    detected_at: "2026-01-30T14:30:00Z",
    ...
  }
}
```

**Embedding Generation:**
Text description of network state ‚Üí SentenceTransformer ‚Üí 384d vector ‚Üí Stored

**Benefits:**
- Semantic search over predictions
- Find similar historical patterns
- Analyze trends over time
- Combine ML + pattern-based alerts

## üéØ Use Cases in Production

### 1. Real-Time Monitoring
```
Every 30s ‚Üí Check all networks ‚Üí Predict conflicts ‚Üí Alert operators
```

### 2. Historical Analysis
```
Query Qdrant ‚Üí "Show all HIGH risk predictions for network FS"
              ‚Üí Analyze patterns leading to conflicts
```

### 3. Similarity Search
```
Current network state ‚Üí Generate embedding ‚Üí Find similar past states
                                           ‚Üí See what happened
                                           ‚Üí Preventive action
```

### 4. Continuous Learning
```
ML Prediction ‚Üí Actual Outcome ‚Üí Feedback Loop ‚Üí Model Improvement
```

## üîß Configuration

### Environment Variables

**Backend (.env):**
```
DIGITAL_TWIN_URL=http://localhost:5002
```

**Digital Twin (.env):**
```
QDRANT_URL=your-qdrant-url
QDRANT_API_KEY=your-api-key
```

### Tuning Parameters

**ML Integration Service (`ml_integration_service.py`):**
```python
SCAN_INTERVAL = 30  # seconds between scans
MIN_PROBABILITY_THRESHOLD = 0.4  # alert threshold
```

**Digital Twin ML Routes:**
```python
DEFAULT_LIMIT = 50  # max predictions returned
```

## üìà Monitoring

### Logs to Watch

**ML Integration Service:**
```
[14:30:00] ‚úì Created 3 pre-conflict alerts
[14:30:30] Network: FS (386 trains)
[14:30:30]   ‚ö†Ô∏è  CONFLICT PREDICTED!
```

**Digital Twin:**
```
‚úÖ ML prediction ml-pred-1706472823.45 stored in Qdrant (point: uuid)
```

**Backend:**
```
POST /api/digital-twin/ml/predictions 200
GET /api/digital-twin/ml/predictions 200
```

## üêõ Troubleshooting

### No ML Predictions Appearing

1. Check ML API is running: `curl http://localhost:5003/api/ml/health`
2. Check ML Integration Service logs
3. Verify Digital Twin is accessible
4. Check Qdrant connection in Digital Twin logs

### Predictions Not in Frontend

1. Check backend proxy is running
2. Verify endpoint: `curl http://localhost:5000/api/digital-twin/ml/predictions`
3. Check browser console for errors
4. Verify PreConflictAlerts component is fetching both endpoints

### Qdrant Storage Issues

1. Check Digital Twin .env has correct QDRANT_URL and QDRANT_API_KEY
2. Verify collection exists: check Qdrant dashboard
3. Check embedding service is generating vectors

## üéâ Success Indicators

When fully integrated, you should see:

‚úÖ ML API serving predictions (port 5003)  
‚úÖ Integration service monitoring networks every 30s  
‚úÖ Predictions stored in Qdrant `pre_conflict_memory`  
‚úÖ Backend proxying ML endpoints  
‚úÖ Frontend displaying ML alerts with ü§ñ icon  
‚úÖ Alerts color-coded by severity (üî¥üü†üü°)  
‚úÖ Both ML and pattern-based alerts in one view  

---

**The ML model is now fully integrated into your Golden Retriever platform!** üöÇ‚ú®
