"""
Test script for Digital Twin enhancements.

This script demonstrates the new features:
1. New conflict types
2. Expanded simulation rules
3. Enhanced explainability
4. Transitland integration (ready)
"""

import asyncio
import sys
from pathlib import Path

# Add parent directory to path
sys.path.insert(0, str(Path(__file__).parent))

from app.core.constants import ConflictType, ConflictSeverity, TimeOfDay, ResolutionStrategy
from app.services.simulation_service import DigitalTwinSimulator, SimulationInput, ResolutionCandidate
from app.services.recommendation_engine import RecommendationEngine
from app.models.conflict import GeneratedConflict


async def test_new_conflict_types():
    """Test simulation with new conflict types."""
    print("=" * 70)
    print("TEST 1: New Conflict Types Simulation")
    print("=" * 70)
    
    simulator = DigitalTwinSimulator(seed=42)
    
    # Test new conflict types
    test_cases = [
        (ConflictType.SIGNAL_FAILURE, "Signal failure at junction"),
        (ConflictType.WEATHER_DISRUPTION, "Heavy fog reducing visibility"),
        (ConflictType.CREW_SHORTAGE, "Driver unavailable for service"),
        (ConflictType.ROLLING_STOCK_FAILURE, "Engine overheating detected"),
    ]
    
    for conflict_type, description in test_cases:
        print(f"\nüìç {conflict_type.value.replace('_', ' ').title()}")
        print(f"   {description}")
        
        sim_input = SimulationInput(
            conflict_type=conflict_type,
            severity=ConflictSeverity.HIGH,
            station="London Euston",
            time_of_day=TimeOfDay.MORNING_PEAK,
            delay_before=15,
            affected_trains=3
        )
        
        # Test best strategy for this conflict type
        candidate = ResolutionCandidate(
            strategy=ResolutionStrategy.REROUTE
        )
        
        result = simulator.simulate(sim_input, candidate)
        
        print(f"   Strategy: {candidate.strategy.value}")
        print(f"   Success: {'‚úÖ' if result.success else '‚ùå'}")
        print(f"   Score: {result.score:.1f}/100")
        print(f"   Delay reduction: {result.delay_reduction} min")
        print(f"   Recovery time: {result.recovery_time} min")


async def test_enhanced_explanations():
    """Test enhanced explanation generation."""
    print("\n" + "=" * 70)
    print("TEST 2: Enhanced Explainability")
    print("=" * 70)
    
    # Create a test conflict
    conflict = {
        "conflict_id": "test-001",
        "conflict_type": ConflictType.ROLLING_STOCK_FAILURE,
        "severity": ConflictSeverity.HIGH,
        "station": "Manchester Piccadilly",
        "time_of_day": TimeOfDay.MORNING_PEAK,
        "delay_before": 20,
        "affected_trains": ["9A05", "1B23", "2C45"],
        "description": "Train 9A05 experiencing mechanical failure at platform 3"
    }
    
    print(f"\nüö® Conflict: {conflict['description']}")
    print(f"   Type: {conflict['conflict_type'].value}")
    print(f"   Severity: {conflict['severity'].value.upper()}")
    print(f"   Current delay: {conflict['delay_before']} minutes")
    
    # Note: Full recommendation engine requires async services
    # For this test, we'll show the explanation structure
    print(f"\nüìä Explanation Format:")
    print(f"   ‚úÖ Strategy Context - WHY this strategy makes sense")
    print(f"   ‚úÖ Historical Evidence - Success rate from similar cases")
    print(f"   ‚úÖ Similarity Metrics - How similar past cases were")
    print(f"   ‚úÖ Simulation Prediction - Expected outcome details")
    print(f"   ‚úÖ Risk Assessment - Confidence and risk level")
    print(f"   ‚úÖ Side Effects - Potential impacts to monitor")


def test_conflict_type_coverage():
    """Test that all conflict types have simulation rules."""
    print("\n" + "=" * 70)
    print("TEST 3: Simulation Rule Coverage")
    print("=" * 70)
    
    from app.services.simulation_service import STRATEGY_EFFECTIVENESS
    
    print(f"\n‚úÖ Coverage Report:")
    all_types = list(ConflictType)
    covered = [ct for ct in all_types if ct in STRATEGY_EFFECTIVENESS]
    
    print(f"   Total conflict types: {len(all_types)}")
    print(f"   Types with rules: {len(covered)}")
    print(f"   Coverage: {len(covered)/len(all_types)*100:.0f}%")
    
    if len(covered) == len(all_types):
        print(f"\n   üéâ All conflict types have simulation rules!")
    else:
        missing = set(all_types) - set(covered)
        print(f"\n   ‚ö†Ô∏è  Missing rules for: {', '.join(t.value for t in missing)}")
    
    # Show some examples
    print(f"\nüìã Sample Rules (Top 3 strategies per type):")
    for conflict_type in [ConflictType.SIGNAL_FAILURE, ConflictType.WEATHER_DISRUPTION]:
        print(f"\n   {conflict_type.value}:")
        strategies = STRATEGY_EFFECTIVENESS[conflict_type]
        top_3 = sorted(strategies.items(), key=lambda x: x[1], reverse=True)[:3]
        for strategy, effectiveness in top_3:
            print(f"      {strategy.value:20s} {effectiveness:.0%}")


def test_transitland_ready():
    """Test that Transitland integration is ready."""
    print("\n" + "=" * 70)
    print("TEST 4: Transitland Integration Status")
    print("=" * 70)
    
    try:
        from app.services.transitland_client import TransitlandClient
        from app.core.config import settings
        
        print(f"\n‚úÖ TransitlandClient imported successfully")
        print(f"‚úÖ API key configured: {'Yes' if hasattr(settings, 'TRANSITLAND_API_KEY') else 'No'}")
        
        # Check UK stations
        print(f"\nüìç Available UK Stations:")
        for i, station in enumerate(list(TransitlandClient.UK_STATIONS.keys())[:5], 1):
            print(f"   {i}. {station}")
        print(f"   ... and {len(TransitlandClient.UK_STATIONS) - 5} more")
        
        print(f"\nüí° To use Transitland data:")
        print(f"   POST /api/v1/conflicts/generate")
        print(f"   {{ \"use_schedule_data\": true, \"schedule_ratio\": 0.7 }}")
        
    except Exception as e:
        print(f"\n‚ùå Error: {e}")


async def main():
    """Run all tests."""
    print("\nüß™ DIGITAL TWIN ENHANCEMENTS - TEST SUITE")
    print("=" * 70)
    
    # Run tests
    await test_new_conflict_types()
    await test_enhanced_explanations()
    test_conflict_type_coverage()
    test_transitland_ready()
    
    print("\n" + "=" * 70)
    print("‚úÖ ALL TESTS COMPLETED")
    print("=" * 70)
    print(f"\nüìö See ENHANCEMENTS-COMPLETE.md for full documentation")


if __name__ == "__main__":
    asyncio.run(main())
